{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b68ae3a-cabf-4cee-b69e-49ff750b113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy\n",
    "from miditoolkit.midi import parser as mid_parser  \n",
    "from miditoolkit.midi import containers as ct\n",
    "from numpy import array, linspace\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from matplotlib.pyplot import plot\n",
    "from scipy.signal import argrelextrema\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43dd2494-712a-4164-bd29-c4b8c4c88aee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Road map\\n----[requirements]\\n0. install requirement\\n    -- pip install -r requirements.txt\\n\\n----[prepare training data]\\n1. turn training data into (-1,512,4)  \\n    : 512 = input_size, \\n    : 4= size of CP token (includingBar (0=new,1=continue,2=pad),Position,Pitch,Duration)\\n    ** DO NOT concatenate all songs tgt, pad every song and make it divisible by 512\\n    ** pad it with (2,16,86,64)\\n    e.g. [ [song1-0:511],[song1-512:520+pad],[song2-0:511],[song2-512-530+pad].... ]\\n    \\n2. Prepare answer dataset \\n    : (0 = padding, 1 = keep, 2 = discard)\\n* save in .npy format\\n* split in 3 different groups\\n    dataroot= ~/data/CP/\\n    -custom_reduction_train.npy , custom_reduction_train_ans.npy\\n    -custom_reduction_valid.npy , custom_reduction_valid_ans.npy\\n    -custom_reduction_test.npy  , custom_reduction_test_ans.npy\\n\\n    \\n----[start fine tuning]\\n1. cd to ./MidiBERT/CP\\n2. python3 finetune.py --task=reduction  --epochs 1 --ckpt xxxxx (default='result/finetune/pretrain_model.ckpt')\\n* gpu with --cuda_devices 0 (+1)\\n\\n----[eval]\\n1. cd to ./MidiBERT/CP\\n2. python3 eval.py --task=reduction\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Road map\n",
    "----[requirements]\n",
    "0. install all requirements\n",
    "    -- pip install -r requirements.txt\n",
    "\n",
    "----[prepare training data]\n",
    "1. turn training data into (-1,512,4)  \n",
    "    : 512 = input_size, \n",
    "    : 4= size of the CP token (Bar (0=new,1=continue,2=pad),Position,Pitch,Duration)\n",
    "    ** DO NOT concatenate all songs tgt, pad every song and make it divisible by 512\n",
    "    ** pad it with (2,16,86,64)\n",
    "    e.g. [ [song1-0:511],[song1-512:520+pad],[song2-0:511],[song2-512-530+pad]] ==> shape(4,512,4)\n",
    "    \n",
    "2. Prepare answer dataset \n",
    "    : (0 = padding, 1 = keep, 2 = discard)\n",
    "* save it in .npy format\n",
    "* split into 3 different groups\n",
    "    put inside ~/data/CP/\n",
    "    -custom_reduction_train.npy , custom_reduction_train_ans.npy\n",
    "    -custom_reduction_valid.npy , custom_reduction_valid_ans.npy\n",
    "    -custom_reduction_test.npy  , custom_reduction_test_ans.npy\n",
    "    \n",
    "** using  .py\n",
    "    - cd to ./prepare_data/CP\n",
    "    - python main.py --task reduction --input_dir \"../../dataset(orchestra only)\"\n",
    "    >files will be saved at ~/data/CP/\n",
    "    >please move all the files to the correct directory\n",
    "\n",
    "\n",
    "    \n",
    "----[start fine tuning]\n",
    "1. cd to ./MidiBERT/CP\n",
    "2. python3 finetune.py --task=reduction  --epochs 1 --ckpt xxxxx (default='result/finetune/pretrain_model.ckpt')\n",
    "* gpu with --cuda_devices 0 (+1)\n",
    "* if gpu is available and --cpu flag is not set, by default it will be trained on GPU\n",
    "\n",
    "----[eval](not finished yet)\n",
    "1. cd to ./MidiBERT/CP\n",
    "2. python3 eval.py --task=reduction\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea1673ff-6a38-4dca-af05-1d4adf991963",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c1c19cd-be01-47b5-bf3b-1eb7a5d49f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 512, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training data after tokenization\n",
    "a=np.load('./data/CP/custom.npy') # after tokenization\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e05cb6e-5d2f-4f9b-9a9e-07e29f475c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#corrsponding ans\n",
    "fake_ans= np.array([[random.randint(1,2) for _ in range(512)] for __ in range(4)])  #random generate\n",
    "fake_ans[3][206:]=0 # random padding\n",
    "fake_ans=fake_ans.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20ddf7f8-5613-40d8-901f-493be9f9a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test,train,valid split\n",
    "#assume a[0],a[1],a[2:] are three different songs\n",
    "testX,testY = a[0].reshape(-1,512,4),fake_ans[0].reshape(-1,512)\n",
    "validX,validY = a[1].reshape(-1,512,4),fake_ans[1].reshape(-1,512)\n",
    "trainX,trainY = a[2:].reshape(-1,512,4),fake_ans[2:].reshape(-1,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73287f6c-b6ed-408e-95bb-c4a3ebaa3157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save training data\n",
    "np.save('./data/CP/custom_reduction_train.npy',trainX)\n",
    "np.save('./data/CP/custom_reduction_train_ans.npy',trainY)\n",
    "np.save('./data/CP/custom_reduction_valid.npy',validX)\n",
    "np.save('./data/CP/custom_reduction_valid_ans.npy',validY)\n",
    "np.save('./data/CP/custom_reduction_test.npy',testX)\n",
    "np.save('./data/CP/custom_reduction_test_ans.npy',testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e08b5b6b-7273-4baa-88d4-81a01fbda0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "Loading Dictionary\n",
      "\n",
      "Loading Dataset\n",
      "X_train: (2, 512, 4), X_valid: (1, 512, 4), X_test: (1, 512, 4)\n",
      "y_train: (2, 512), y_valid: (1, 512), y_test: (1, 512)\n",
      "   len of train_loader 1\n",
      "   len of valid_loader 1\n",
      "   len of valid_loader 1\n",
      "\n",
      "Building BERT model\n",
      "   Loading pre-trained model from pretrain_model.ckpt"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anacnda\\envs\\RL\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:42<00:00, 42.08s/it]\n",
      "100%|██████████| 1/1 [00:42<00:00, 42.76s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:25<00:00, 25.37s/it]\n",
      "100%|██████████| 1/1 [00:26<00:00, 26.03s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:21<00:00, 21.90s/it]\n",
      "100%|██████████| 1/1 [00:22<00:00, 22.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Creating Finetune Trainer using index layer -1\n",
      "   device: cpu\n",
      "init a fine-tune model, sequence-level task? False\n",
      "\n",
      "Training Start\n",
      "   save model at C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/result/finetune/reduction_\\model.ckpt\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "1\n",
      "513.0\n",
      "epoch: 1/1 | Train Loss: 1.0158 | Train acc: 0.4937 | Valid Loss: 0.8541 | Valid acc: 0.4971 | Test loss: 0.857 | Test acc: 0.5049\n"
     ]
    }
   ],
   "source": [
    "# start fine tuning\n",
    "! python ./MidiBERT/CP/finetune.py --task=reduction --epochs 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea09a7d-7759-4466-beb9-d96d20bbff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval\n",
    "'''\n",
    "procedure:\n",
    "1. use prepare_data to tokenlize *a* song to .npy format\n",
    "    -- it should be saved under ~/data/CP\n",
    "2. cd to ~/MidiBERT/CP\n",
    "3. python eval.py --task reduction --case [file name of the .npy file]\n",
    "3. two mid are generated \n",
    "\n",
    "\n",
    "--[sample]\n",
    "1. put orchestra.mid into testcase folder *(the file should only contain 1 file)*\n",
    "2. cd ./prepare_data/CP\n",
    "3. python .\\main.py --task custom --name testcase1 --input_dir ../../testcase\n",
    "4. cd ../../MidiBERT/CP\n",
    "5. python eval --task reduction --case testcase1\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
