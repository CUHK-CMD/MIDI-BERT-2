{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "450bf21f-0e49-42db-8cea-f66c96041606",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-v40uhh5o because the default path (/uac/ascstd/wkwong/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "from miditoolkit.midi import parser as mid_parser  \n",
    "from miditoolkit.midi import containers as ct\n",
    "from transformers import BertConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "from MidiBERT.model import MidiBertSeq2Seq\n",
    "from MidiBERT.modelLM import MidiBertSeq2SeqComplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b76f3962-12d0-489c-8522-be4384fcfaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([29, 512, 6]) torch.Size([29, 513, 6])\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "skyline_max_len = 90\n",
    "hs = 768\n",
    "seq_len = 512\n",
    "token_len = 6\n",
    "\n",
    "e2w, w2e = np.load('dict/CP_program.pkl', allow_pickle=True)\n",
    "X = np.load('s2s_test.npy', allow_pickle=True)\n",
    "y = np.load('s2s_test_ans.npy', allow_pickle=True)\n",
    "X, y = torch.tensor(X), torch.tensor(y)\n",
    "\n",
    "print(X.shape,y.shape)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.15, random_state=42\n",
    "# )\n",
    "# print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8598ea1-5d96-4720-b301-6a2a6a0ad1bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_en = BertConfig(\n",
    "    max_position_embeddings=seq_len,\n",
    "    position_embedding_type=\"relative_key_query\",\n",
    "    hidden_size=hs,\n",
    ")\n",
    "config_de = BertConfig(\n",
    "    max_position_embeddings=seq_len,\n",
    "    position_embedding_type=\"relative_key_query\",\n",
    "    hidden_size=hs,\n",
    ")\n",
    "config_de.is_decoder = True\n",
    "config_de.add_cross_attention = True\n",
    "midibert = MidiBertSeq2Seq(config_en, config_de, None,None, e2w, w2e)\n",
    "\n",
    "model = MidiBertSeq2SeqComplete(midibert).to(device)\n",
    "model.eval()\n",
    "\n",
    "checkpoint = torch.load('result/seq2seq/4bos_prevpretrain/model_best-acc_epoch=41_loss=0.594_acc=0.9329495798319328.ckpt')\n",
    "for key in list(checkpoint[\"state_dict\"].keys()):\n",
    "            # rename the states in checkpoint\n",
    "            checkpoint[\"state_dict\"][key.replace(\"module.\", \"\")] = checkpoint[\n",
    "                \"state_dict\"\n",
    "            ].pop(key)\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00fb1af4-19a3-48cd-b2d7-f6d76405824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS1 = np.array([midibert.e2w[etype][\"%s <BOS1>\" % etype] for etype in midibert.e2w])\n",
    "BOS2 = np.array([midibert.e2w[etype][\"%s <BOS2>\" % etype] for etype in midibert.e2w])\n",
    "BOS3 = np.array([midibert.e2w[etype][\"%s <BOS3>\" % etype] for etype in midibert.e2w])\n",
    "BOS4 = np.array([midibert.e2w[etype][\"%s <BOS4>\" % etype] for etype in midibert.e2w])\n",
    "BOSs = [BOS1,BOS2,BOS3,BOS4]\n",
    "PAD = np.array([midibert.e2w[etype][\"%s <PAD>\" % etype] for etype in midibert.e2w])\n",
    "EOS = np.array([midibert.e2w[etype][\"%s <EOS>\" % etype] for etype in midibert.e2w])\n",
    "ABS = np.array([midibert.e2w[etype][\"%s <ABS>\" % etype] for etype in midibert.e2w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3688845-d868-4cd6-9cfa-04bc4bfe5565",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def inference(token,idx):\n",
    "    token = token.reshape((1, seq_len, token_len))\n",
    "    token = token.to(device)\n",
    "    attn_mask_encoder = (\n",
    "        (token[:, :, 0] != midibert.bar_pad_word)\n",
    "        .float()\n",
    "        .to(device)\n",
    "    )  # (batch, seq_len)\n",
    "\n",
    "    outputs = np.array([BOSs[idx]])\n",
    "    for i in range(seq_len):\n",
    "        decoder_input_ids = np.array([np.vstack((outputs, np.tile(midibert.pad_word_np, (seq_len - 1 - i, 1))))])\n",
    "        # assert decoder_input_ids.shape == (1, seq_len, token_len)\n",
    "        decoder_input_ids = torch.from_numpy(decoder_input_ids).to(device)\n",
    "        attn_mask_decoder = (\n",
    "            (decoder_input_ids[:, :, 0] != midibert.bar_pad_word)\n",
    "            .float()\n",
    "            .to(device)\n",
    "        )  # (batch, seq_len)\n",
    "\n",
    "        # tuples of size 6, each element is a tensor with shape: (batch, seq_len, n_tokens)\n",
    "        predicted_word = model(token, decoder_input_ids, attn_mask_encoder, attn_mask_decoder)\n",
    "\n",
    "        # event to word\n",
    "        temp = []\n",
    "        for j, etype in enumerate(midibert.e2w):\n",
    "            o = np.argmax(predicted_word[j].cpu().detach().numpy(), axis=-1)\n",
    "            temp.append(o)\n",
    "        temp = np.stack(temp, axis=-1)[0][i]\n",
    "        \n",
    "        # stop generating when EOS or PAD is generated\n",
    "        is_end = (temp == EOS).all() or (temp == PAD).all()\n",
    "        print(f'Generated {i} notes', end=\"\\n\" if is_end else \"\\r\")\n",
    "        if is_end:\n",
    "            break\n",
    "        outputs = np.vstack((outputs, temp))\n",
    "\n",
    "    outputs = outputs[1:]\n",
    "    last_pos = 999\n",
    "    changed = 0\n",
    "    for i, tk in enumerate(outputs):\n",
    "        if tk[1] >= last_pos and tk[0] == 0:\n",
    "            outputs[i][0] = 1\n",
    "            changed += 1\n",
    "        last_pos = tk[1]\n",
    "    print(f\"Changed {changed} tokens\")\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb1f557f-0922-47d8-bf85-6829710259ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token2mid(pages, out_path):\n",
    "    # meta data\n",
    "    out = mid_parser.MidiFile()\n",
    "    out.ticks_per_beat = 480\n",
    "    instruments_type = [40,40,41,42]\n",
    "    for t in instruments_type:\n",
    "        out.instruments.append(ct.Instrument(program=t,is_drum=False,name='reduction'))\n",
    "\n",
    "    # First Time Signature\n",
    "    ts = int(pages[0][0][5]+2)\n",
    "    last_ts = ts\n",
    "    current_beat = -ts*480\n",
    "    out.time_signature_changes.append(ct.TimeSignature(ts, 4, 0))\n",
    "\n",
    "    for instrument,page in enumerate(pages):\n",
    "        for idx, n in enumerate(page):\n",
    "            # Stop if end or padding starts\n",
    "            if (n == EOS).all() or (n == PAD).all():\n",
    "                break\n",
    "\n",
    "            # Time Signature for THIS note\n",
    "            ts = int(page[idx][5]+2)\n",
    "\n",
    "            # Bar moves forward\n",
    "            if n[0] == 0 or (n[:-1] == ABS[:-1]).all():\n",
    "                current_beat += last_ts*480\n",
    "\n",
    "            # Update new Time Signature if any\n",
    "            if ts != last_ts:\n",
    "                last_ts = ts\n",
    "                out.time_signature_changes.append(ct.TimeSignature(ts, 4, current_beat))\n",
    "\n",
    "            # Add THIS note\n",
    "            if (n[:-1] != ABS[:-1]).all():\n",
    "#                 program = n[4]\n",
    "#                 if program not in [i.program for i in out.instruments]:\n",
    "#                     out.instruments.append(ct.Instrument(program=program, is_drum=False, name='reduction'))\n",
    "#                     instrument = out.instruments[-1]\n",
    "#                 else:\n",
    "#                     index = [i.program for i in out.instruments].index(program)\n",
    "#                     instrument = out.instruments[index]\n",
    "                out.instruments[instrument].notes.append(\n",
    "                    ct.Note(\n",
    "                        start=int(current_beat + n[1]*480/12),\n",
    "                        end=int(current_beat + (n[1]+n[3]+1)*(480/12)),\n",
    "                        pitch=n[2] + 22,\n",
    "                        velocity=90\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    out.dump(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15daa2cb-2d0b-43e4-a211-e377a686030e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 notes\n",
      "Changed 0 tokens\n",
      "Generated 0 notes\n",
      "Changed 0 tokens\n",
      "Generated 0 notes\n",
      "Changed 0 tokens\n",
      "Generated 0 notes\n",
      "Changed 0 tokens\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m channel_3 \u001b[38;5;241m=\u001b[39m inference(X_test,\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     11\u001b[0m channel_4 \u001b[38;5;241m=\u001b[39m inference(X_test,\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtoken2mid\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchannel_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchannel_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchannel_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchannel_4\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./test_gen.mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mtoken2mid\u001b[0;34m(pages, out_path)\u001b[0m\n\u001b[1;32m      7\u001b[0m     out\u001b[38;5;241m.\u001b[39minstruments\u001b[38;5;241m.\u001b[39mappend(ct\u001b[38;5;241m.\u001b[39mInstrument(program\u001b[38;5;241m=\u001b[39mt,is_drum\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreduction\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# First Time Signature\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m ts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mpages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     11\u001b[0m last_ts \u001b[38;5;241m=\u001b[39m ts\n\u001b[1;32m     12\u001b[0m current_beat \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mts\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m480\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# get one sample\n",
    "X_test = X[28, :, :]\n",
    "y_test = y[28, 1:, :]\n",
    "\n",
    "token2mid([y_test.cpu().detach().numpy()], \"./test_ans.mid\")\n",
    "token2mid([X_test.cpu().detach().numpy()], \"./test_input.mid\")\n",
    "\n",
    "channel_1 = inference(X_test,0)\n",
    "channel_2 = inference(X_test,1)\n",
    "channel_3 = inference(X_test,2)\n",
    "channel_4 = inference(X_test,3)\n",
    "token2mid([channel_1,channel_2,channel_3,channel_4], \"./test_gen.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c2a883e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 6])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92eb7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
