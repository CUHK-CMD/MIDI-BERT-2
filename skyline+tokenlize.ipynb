{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64c78001-8ca5-4780-b1e5-9420d9b4b350",
   "metadata": {},
   "source": [
    "# skyline (helper functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cc6284b-a770-4e73-9eb4-19179e04029d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mergeIntervals(arr):\n",
    "        # Sorting based on the increasing order \n",
    "        # of the start intervals\n",
    "        arr.sort(key = lambda x: x[0]) \n",
    "        # array to hold the merged intervals\n",
    "        m = []\n",
    "        s = -10000\n",
    "        max = -100000\n",
    "        for i in range(len(arr)):\n",
    "            a = arr[i]\n",
    "            if a[0] > max:\n",
    "                if i != 0:\n",
    "                    m.append([s,max])\n",
    "                max = a[1]\n",
    "                s = a[0]\n",
    "            else:\n",
    "                if a[1] >= max:\n",
    "                    max = a[1]        \n",
    "        #'max' value gives the last point of \n",
    "        # that particular interval\n",
    "        # 's' gives the starting point of that interval\n",
    "        # 'm' array contains the list of all merged intervals\n",
    "        if max != -100000 and [s, max] not in m:\n",
    "            m.append([s, max])\n",
    "        return m\n",
    "\n",
    "def gettop(note,intervals):\n",
    "    note_interval = [note[4],note[5]]#onset,offset\n",
    "    overlap_time = 0\n",
    "    total_time = note[5] - note[4]\n",
    "    if total_time == 0:\n",
    "        return 1 #(we do not need this note)\n",
    "    for interval in intervals:\n",
    "        maxstart = max(note_interval[0],interval[0])\n",
    "        minend = min(note_interval[1],interval[1])\n",
    "        if maxstart < minend:\n",
    "            overlap_time += minend-maxstart\n",
    "    return overlap_time/total_time\n",
    "\n",
    "def skyline(notes): #revised skyline algorithm by Chai, 2000\n",
    "    #Performed on a single channel\n",
    "    accepted_notes = []\n",
    "    notes = sorted(notes, key=lambda x: x[2], reverse=True) #sort by pitch\n",
    "    intervals = []\n",
    "    for note in notes:\n",
    "        if gettop(note,intervals) <=0.5:\n",
    "            accepted_notes.append(note)\n",
    "            intervals.append([note[4],note[5]]) #onset,offset\n",
    "            intervals = mergeIntervals(intervals)\n",
    "    return sorted(accepted_notes,key=lambda x: (x[4],x[0])) #sort by onset & bar(new)\n",
    "    \n",
    "def skyline_reverse(notes): #revised skyline algorithm by Chai, 2000\n",
    "    #Performed on a single channel\n",
    "    accepted_notes = []\n",
    "    notes = sorted(notes, key=lambda x: x[2]) #sort by pitch\n",
    "    intervals = []\n",
    "    for note in notes:\n",
    "        if gettop(note,intervals) <=0.8:\n",
    "            accepted_notes.append(note)\n",
    "            intervals.append([note[4],note[5]]) #onset,offset\n",
    "            intervals = mergeIntervals(intervals)\n",
    "    return sorted(accepted_notes,key=lambda x: (x[4],x[0])) #sort by onset & bar(new)\n",
    "\n",
    "def align_token(notes,length):\n",
    "    out=[]\n",
    "    bar=[]\n",
    "    bar_count=0\n",
    "    seen_first=False\n",
    "    tpb=480\n",
    "    note_idx=0\n",
    "    while note_idx<len(notes):\n",
    "        note=notes[note_idx]\n",
    "        if bar_count*4*tpb<=note[4]<(bar_count+1)*tpb*4: #within current bar\n",
    "            bar.append(note[:4])\n",
    "            if (seen_first==True and note[0]==0):\n",
    "                print(note,note_idx,notes)\n",
    "            assert(not(seen_first==True and note[0]==0)) #no two 0(newbar) within the same bar\n",
    "            if not seen_first :\n",
    "                seen_first=True\n",
    "                bar[-1][0]=0\n",
    "            note_idx+=1\n",
    "        else:            \n",
    "            #assert(len(bar)>0)\n",
    "            if len(bar)>0:\n",
    "                out.append(bar)\n",
    "            else:\n",
    "                out.append([list(ABS)])\n",
    "            bar=[]\n",
    "            bar_count+=1\n",
    "            seen_first=False\n",
    "    \n",
    "    #assert(len(bar)>0)\n",
    "    if len(bar)>0:\n",
    "        out.append(bar)\n",
    "    else:\n",
    "        out.append([list(ABS)])\n",
    "\n",
    "    bar=[]\n",
    "    bar_count+=1\n",
    "    seen_first=False\n",
    "    \n",
    "\n",
    "    assert(bar_count==length)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53fc833-ea25-4ebd-8b4f-6216b51bd09d",
   "metadata": {},
   "source": [
    "# tokenlize data\n",
    "## tokenlize all .mid files inside a folder\n",
    "### source data: PianoMidi_nicely_formatted\n",
    "<code> cd ~/prepare_data/CP</code>\n",
    "\n",
    "<code> python main.py --task skyline --input_dir ../../skyline_data --output_dir ../../sktline_data --name skylineNPY --dict ../../dict/CP_skyline.pkl</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "450bf21f-0e49-42db-8cea-f66c96041606",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "543bf431-dfaf-4573-924e-dc59ce6b1797",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=np.load('./skyline_data/skylineNPY.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a7c20da-c3ef-4600-99af-28fbb233ed9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1683, 512, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "840484e3-ac77-40d3-8f94-d5bdd7e80ff3",
   "metadata": {},
   "source": [
    "#test data\n",
    "tokens=np.array([  ([[0,0,40,0]]+[[1,0,40,0]])*256  ,([[0,0,40,0]]+[[1,0,40,0]])*255+[[4,18,88,66],[2,16,86,64]] ])\n",
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cf804e5-7e95-4aed-ae23-7cc96c92440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref to ./dict/CP_skyline.pkl\n",
    "PAD=np.array([2,16,86,64]) # --> padding\n",
    "EOS=np.array([4,18,88,66]) # --> End of input segment\n",
    "ABS=np.array([5,19,89,67]) #--> empty bar by skyline algo, (e.g. skyline pick a long note from the bar ahead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "739207b6-c9ee-402a-a34d-fc86a5e6cbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_by_song=[]\n",
    "last_idx=0\n",
    "for idx,page in enumerate(tokens):\n",
    "    if (page[-1] == PAD).all() or (page[-1] == EOS).all():\n",
    "        tokens_by_song.append(tokens[last_idx:idx+1])\n",
    "        last_idx=idx+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c226ef36-8d6a-43b1-8ae0-0537dd1d0b56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skyline_max_len=100\n",
    "full_max_len=600\n",
    "temp_skyline=[]\n",
    "allsong_skyline_tokens=[]\n",
    "allsong_full_tokens=[]\n",
    "max_token_len=0\n",
    "for song in tokens_by_song:\n",
    "    current_bar=-1\n",
    "    tpb=480\n",
    "    token_with_on_off_set=[]\n",
    "    skyline_tokens=[]\n",
    "    full_tokens=[]\n",
    "    for page in song:\n",
    "        for token in page:\n",
    "            if not((token==PAD).all() or (token==EOS).all()):\n",
    "                if token[0]==0:\n",
    "                    current_bar+=1\n",
    "                temp=list(token)\n",
    "                temp.append(int(current_bar*4*tpb+token[1]*tpb/4))  #onset\n",
    "                temp.append(int(current_bar*4*tpb+token[1]*tpb/4+(token[3]+1)*tpb/8))  #offset\n",
    "                token_with_on_off_set.append(temp)\n",
    "    \n",
    "    #skyline\n",
    "    total_bar=current_bar+1\n",
    "    org=align_token(token_with_on_off_set,total_bar)\n",
    "    sl=skyline(token_with_on_off_set)+skyline_reverse(token_with_on_off_set)\n",
    "    #remove duplication\n",
    "    sl = [tuple(x) for x in sl]\n",
    "    sl = list(dict.fromkeys(sl))\n",
    "    sl = [list(x) for x in sl]\n",
    "    sl=sorted(sl,key=lambda x: (x[4],x[0])) #sort by onset & bar(new)\n",
    "    sl=align_token(sl,total_bar)\n",
    "    \n",
    "    #output\n",
    "    current_bar=0\n",
    "    temp_skyline=[]\n",
    "    temp_full=[]\n",
    "    while current_bar<total_bar:\n",
    "        while current_bar<total_bar and len(temp_skyline)+len(sl[current_bar])<skyline_max_len:\n",
    "            temp_skyline+=sl[current_bar]\n",
    "            temp_full+=org[current_bar]\n",
    "            current_bar+=1\n",
    "        assert(0<len(temp_skyline)<skyline_max_len and 0<len(temp_full)<full_max_len ) # at least it shld hv the ABS token\n",
    "        #add EOS\n",
    "        temp_skyline.append(EOS)\n",
    "        temp_full.append(EOS)\n",
    "        temp_skyline=np.array(temp_skyline).reshape(-1,4)\n",
    "        temp_full=np.array(temp_full).reshape(-1,4)\n",
    "        #pad\n",
    "        while len(temp_skyline)<skyline_max_len:            \n",
    "            temp_skyline=np.vstack((temp_skyline,PAD))\n",
    "        if len(temp_full)>max_token_len:\n",
    "            max_token_len=len(temp_full)\n",
    "        while len(temp_full)<full_max_len:\n",
    "            temp_full=np.vstack((temp_full,PAD))\n",
    "        skyline_tokens.append(temp_skyline)\n",
    "        full_tokens.append(temp_full)\n",
    "        temp_skyline=[]\n",
    "        temp_full=[]\n",
    "        \n",
    "    assert(len(allsong_skyline_tokens)==len(allsong_full_tokens))\n",
    "    for batch in skyline_tokens:\n",
    "        allsong_skyline_tokens.append(batch)\n",
    "    for batch in full_tokens:\n",
    "        allsong_full_tokens.append(batch)\n",
    "allsong_skyline_tokens=np.array(allsong_skyline_tokens)\n",
    "allsong_full_tokens=np.array(allsong_full_tokens)        \n",
    "assert(allsong_skyline_tokens.shape[0]==allsong_full_tokens.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93141e58-5733-4dda-8fe3-b19fb99905ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "504"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_token_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3507c8d5-55be-45a9-9860-d25190c2d3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5793, 100, 4), (5793, 600, 4))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allsong_skyline_tokens.shape,allsong_full_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "898948a2-965a-4f43-9486-ffe1d37a91f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('skyline_data/skyline_tokens.npy', 'wb') as f1:\n",
    "    np.save(f1, allsong_skyline_tokens)\n",
    "with open('skyline_data/full_tokens.npy', 'wb') as f2:\n",
    "    np.save(f2, allsong_full_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
