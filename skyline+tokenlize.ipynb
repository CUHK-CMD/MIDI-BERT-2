{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "173fa3e7-9273-49dc-b3ea-785b4fa98dcb",
   "metadata": {},
   "source": [
    "# library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "450bf21f-0e49-42db-8cea-f66c96041606",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy as np\n",
    "import numpy\n",
    "from miditoolkit.midi import parser as mid_parser  \n",
    "from miditoolkit.midi import containers as ct\n",
    "from numpy import array, linspace\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from matplotlib.pyplot import plot\n",
    "from scipy.signal import argrelextrema\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c78001-8ca5-4780-b1e5-9420d9b4b350",
   "metadata": {},
   "source": [
    "# skyline (helper functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cc6284b-a770-4e73-9eb4-19179e04029d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mergeIntervals(arr):\n",
    "        # Sorting based on the increasing order \n",
    "        # of the start intervals\n",
    "        arr.sort(key = lambda x: x[0]) \n",
    "        # array to hold the merged intervals\n",
    "        m = []\n",
    "        s = -10000\n",
    "        max = -100000\n",
    "        for i in range(len(arr)):\n",
    "            a = arr[i]\n",
    "            if a[0] > max:\n",
    "                if i != 0:\n",
    "                    m.append([s,max])\n",
    "                max = a[1]\n",
    "                s = a[0]\n",
    "            else:\n",
    "                if a[1] >= max:\n",
    "                    max = a[1]        \n",
    "        #'max' value gives the last point of \n",
    "        # that particular interval\n",
    "        # 's' gives the starting point of that interval\n",
    "        # 'm' array contains the list of all merged intervals\n",
    "        if max != -100000 and [s, max] not in m:\n",
    "            m.append([s, max])\n",
    "        return m\n",
    "\n",
    "def gettop(note,intervals):\n",
    "    note_interval = [note[4],note[5]]#onset,offset\n",
    "    overlap_time = 0\n",
    "    total_time = note[5] - note[4]\n",
    "    if total_time == 0:\n",
    "        return 1 #(we do not need this note)\n",
    "    for interval in intervals:\n",
    "        maxstart = max(note_interval[0],interval[0])\n",
    "        minend = min(note_interval[1],interval[1])\n",
    "        if maxstart < minend:\n",
    "            overlap_time += minend-maxstart\n",
    "    return overlap_time/total_time\n",
    "\n",
    "def skyline(notes): #revised skyline algorithm by Chai, 2000\n",
    "    #Performed on a single channel\n",
    "    accepted_notes = []\n",
    "    notes = sorted(notes, key=lambda x: x[2], reverse=True) #sort by pitch\n",
    "    intervals = []\n",
    "    for note in notes:\n",
    "        if gettop(note,intervals) <=0.5:\n",
    "            accepted_notes.append(note)\n",
    "            intervals.append([note[4],note[5]]) #onset,offset\n",
    "            intervals = mergeIntervals(intervals)\n",
    "    return sorted(accepted_notes,key=lambda x: (x[4],x[0])) #sort by onset & bar(new)\n",
    "    \n",
    "def skyline_reverse(notes): #revised skyline algorithm by Chai, 2000\n",
    "    #Performed on a single channel\n",
    "    accepted_notes = []\n",
    "    notes = sorted(notes, key=lambda x: x[2]) #sort by pitch\n",
    "    intervals = []\n",
    "    for note in notes:\n",
    "        if gettop(note,intervals) <=0.8:\n",
    "            accepted_notes.append(note)\n",
    "            intervals.append([note[4],note[5]]) #onset,offset\n",
    "            intervals = mergeIntervals(intervals)\n",
    "    return sorted(accepted_notes,key=lambda x: (x[4],x[0])) #sort by onset & bar(new)\n",
    "\n",
    "def align_token(notes,length):                                   #align the tokens bar by bar\n",
    "    out=[]\n",
    "    bar=[]\n",
    "    bar_count=0\n",
    "    seen_first=False\n",
    "    tpb=480\n",
    "    note_idx=0\n",
    "    \n",
    "    while note_idx<len(notes):\n",
    "        note=notes[note_idx]\n",
    "        if bar_count*4*tpb<=note[4]<(bar_count+1)*tpb*4:         #within current bar\n",
    "            bar.append(note[:4])\n",
    "            if (seen_first==True and note[0]==0):\n",
    "                print(note,note_idx,notes)\n",
    "            assert(not(seen_first==True and note[0]==0))         #ASSERT: no two 0(newbar) within the same bar\n",
    "            if not seen_first :\n",
    "                seen_first=True\n",
    "                bar[-1][0]=0\n",
    "            note_idx+=1\n",
    "        else:            \n",
    "            #assert(len(bar)>0)\n",
    "            if len(bar)>0:                                       # add <ABS> if it is an empty bar\n",
    "                out.append(bar)\n",
    "            else:\n",
    "                out.append([list(ABS)])\n",
    "            bar=[]\n",
    "            bar_count+=1\n",
    "            seen_first=False\n",
    "    \n",
    "\n",
    "    if len(bar)>0:                                               # add <ABS> if it is an empty bar\n",
    "        out.append(bar)\n",
    "    else:\n",
    "        out.append([list(ABS)])\n",
    "\n",
    "    bar=[]\n",
    "    bar_count+=1\n",
    "    seen_first=False\n",
    "    \n",
    "\n",
    "    assert(bar_count==length)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53fc833-ea25-4ebd-8b4f-6216b51bd09d",
   "metadata": {},
   "source": [
    "# README\n",
    "### tokenlize all .mid files inside a folder\n",
    "source data: PianoMidi_nicely_formatted\n",
    "\n",
    "<code> cd ~/prepare_data/CP</code>\n",
    "\n",
    "<code> python main.py --task skyline --input_dir ../../skyline_data --output_dir ../../sktline_data --name skylineNPY --dict ../../dict/CP_skyline.pkl</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "543bf431-dfaf-4573-924e-dc59ce6b1797",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=np.load('./skyline_data/skylineNPY.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a7c20da-c3ef-4600-99af-28fbb233ed9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1683, 512, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "840484e3-ac77-40d3-8f94-d5bdd7e80ff3",
   "metadata": {},
   "source": [
    "#test data\n",
    "tokens=np.array([  ([[0,0,40,0]]+[[1,0,40,0]])*256  ,([[0,0,40,0]]+[[1,0,40,0]])*255+[[4,18,88,66],[2,16,86,64]] ])\n",
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cf804e5-7e95-4aed-ae23-7cc96c92440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref to ./dict/CP_skyline.pkl\n",
    "PAD=np.array([2,16,86,64])                                                                               # --> padding\n",
    "EOS=np.array([4,18,88,66])                                                                               # --> End of input segment\n",
    "ABS=np.array([5,19,89,67])                                                                               #--> empty bar produced by the skyline algo, \n",
    "                                                                                                         #    (e.g. skyline pick a long note from the bar ahead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "739207b6-c9ee-402a-a34d-fc86a5e6cbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_by_song=[]                                                                                        #group tokens by song, ragged array in shape:(N,) \n",
    "last_idx=0\n",
    "for idx,page in enumerate(tokens):\n",
    "    if (page[-1] == PAD).all() or (page[-1] == EOS).all():\n",
    "        tokens_by_song.append(tokens[last_idx:idx+1])\n",
    "        last_idx=idx+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c226ef36-8d6a-43b1-8ae0-0537dd1d0b56",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-010421731faf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0mtotal_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurrent_bar\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m                                                                                \u001b[1;31m#skyline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0morg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malign_token\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_with_on_off_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtotal_bar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[0msl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskyline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_with_on_off_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mskyline_reverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_with_on_off_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[0msl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msl\u001b[0m\u001b[1;33m]\u001b[0m                                                                            \u001b[1;31m#remove duplication\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-17e89b14f69d>\u001b[0m in \u001b[0;36mskyline_reverse\u001b[1;34m(notes)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mintervals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnote\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnotes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mgettop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mintervals\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m             \u001b[0maccepted_notes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnote\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mintervals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnote\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnote\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#onset,offset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-17e89b14f69d>\u001b[0m in \u001b[0;36mgettop\u001b[1;34m(note, intervals)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;31m#(we do not need this note)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0minterval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mintervals\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mmaxstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnote_interval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minterval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mminend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnote_interval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minterval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmaxstart\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mminend\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "Repackage the tokens:\n",
    "\n",
    "const: (pick randomly)\n",
    "   skyline_max_len: 100\n",
    "   full_max_len: 600 <-- this may need to be adjusted if the data is orchestra score (i guess around 1200?)\n",
    "   * provided that the max_len encoutered so far is around 500 in PianoMidi_nively_formatted dataset, \n",
    "\n",
    "input:\n",
    "    tokens_by_song:           Ragged integer array in shape(#song, ) \n",
    "output:\n",
    "    allsong_skyline_tokens    Integer array in shape(-1,skyline_max_len,4)\n",
    "    allsong_full_tokens       Integer array in shape(-1,full_max_len,4)\n",
    "    \n",
    "description:\n",
    "    Assumption in this section:\n",
    "    * Let 0<=N<len(allsong_skyline_tokens)\n",
    "    * assert(len(allsong_skyline_tokens) == len(allsong_full_tokens))\n",
    "    \n",
    "    allsong_skyline_tokens is paired with allsong_full_tokens\n",
    "        - e.g. allsong_skyline_tokens[N] and allsong_full_tokens[N] represent the same section in the same score\n",
    "        - IF allsong_skyline_tokens[N] contains 10 bars, allsong_full_tokens[N] will only contain the same (10) bars\n",
    "          even if it has plenty of space lefts\n",
    "          \n",
    "    Two extra tokens:\n",
    "        - <EOS>[4,18,88,66]: indicate the end of allsong_skyline_tokens[N] or allsong_full_tokens[N]\n",
    "        - <ABS>[5,19,89,67]: indicate a empty bar\n",
    "        - <PAD>[2,16,86,64]: indicate a pad\n",
    "\n",
    "example:\n",
    "    input:\n",
    "          [\n",
    "             [[0,0,20,10],[1,0,10,10],[1,0,90,10],[0,0,50,0]]\n",
    "          ]\n",
    "    \n",
    "    output:\n",
    "        allsong_skyline_tokens=[\n",
    "                                    [[0,0,10,10],[1,0,90,10],[5,19,89,67],[4,18,88,66],[2,16,86,64]................. ]\n",
    "                                ]\n",
    "        allsong_full_tokens=[\n",
    "                                   [[0,0,20,10],[1,0,10,10],[1,0,90,10],[0,0,50,0],[4,18,88,66],[2,16,86,64].................] \n",
    "                            ]\n",
    "                            \n",
    "implementation:\n",
    "    1. add onset & offset to each token\n",
    "    2. reuse the skyline&skyline_reverse functions\n",
    "    3. combine the results and filter out duplicated tokens AS skyline_tokens\n",
    "    4. align the skyline_tokens and the original tokens bar by bar\n",
    "        skyine_tokens = remaining notes after skyline algorithm\n",
    "        full_tokens = all original notes\n",
    "    3. DO\n",
    "            DO\n",
    "            Let N = the maximum number of subsequence bar such that the total #tokens do not exceed \"skyline_max_len\"\n",
    "            3.1 extract all skyline_tokens within that N bars into \"temp_skyline\"\n",
    "            3.2 extract all tokens within that N bars into \"temp_full\" with assertion (#token <\"full_max_len\")\n",
    "            3.3 add <EOS> to \"temp_skyline\" and \"temp_full\"\n",
    "            3.3 pad both \"temp_skyline\" and \"temp_full\"\n",
    "            3.4 repeat until all tokens inside the song are processed\n",
    "        repeat until all songs are processed\n",
    "'''\n",
    "\n",
    "\n",
    "skyline_max_len=100                                                                                      # parameters\n",
    "full_max_len=600\n",
    "temp_skyline=[]\n",
    "allsong_skyline_tokens=[]\n",
    "allsong_full_tokens=[]\n",
    "max_token_len=0\n",
    "\n",
    "for song in tokens_by_song:     \n",
    "    \n",
    "    current_bar=-1                                                                                       #add onset &offset on each token\n",
    "    tpb=480\n",
    "    token_with_on_off_set=[]\n",
    "    skyline_tokens=[]\n",
    "    full_tokens=[]\n",
    "    for page in song:\n",
    "        for token in page:\n",
    "            if not((token==PAD).all() or (token==EOS).all()):\n",
    "                if token[0]==0:\n",
    "                    current_bar+=1\n",
    "                temp=list(token)\n",
    "                temp.append(int(current_bar*4*tpb+token[1]*tpb/4))                                        #onset\n",
    "                temp.append(int(current_bar*4*tpb+token[1]*tpb/4+(token[3]+1)*tpb/8))                     #offset\n",
    "                token_with_on_off_set.append(temp)\n",
    "                \n",
    "    \n",
    "    \n",
    "    total_bar=current_bar+1                                                                                #skyline\n",
    "    org=align_token(token_with_on_off_set,total_bar)\n",
    "    sl=skyline(token_with_on_off_set)+skyline_reverse(token_with_on_off_set)\n",
    "    \n",
    "    sl = [tuple(x) for x in sl]                                                                            #remove duplication\n",
    "    sl = list(dict.fromkeys(sl))\n",
    "    sl = [list(x) for x in sl]\n",
    "    sl=sorted(sl,key=lambda x: (x[4],x[0])) #sort by onset & bar(new)\n",
    "    sl=align_token(sl,total_bar)\n",
    "    \n",
    "    \n",
    "    current_bar=0\n",
    "    temp_skyline=[]\n",
    "    temp_full=[]\n",
    "    while current_bar<total_bar:\n",
    "        while current_bar<total_bar and len(temp_skyline)+len(sl[current_bar])<skyline_max_len:\n",
    "            temp_skyline+=sl[current_bar]\n",
    "            temp_full+=org[current_bar]\n",
    "            current_bar+=1\n",
    "        assert(0<len(temp_skyline)<skyline_max_len and 0<len(temp_full)<full_max_len )                     #at least it shld has the ABS token\n",
    "        \n",
    "        temp_skyline.append(EOS)                                                                           #add EOS\n",
    "        temp_full.append(EOS)\n",
    "        temp_skyline=np.array(temp_skyline).reshape(-1,4)\n",
    "        temp_full=np.array(temp_full).reshape(-1,4)\n",
    "        \n",
    "        while len(temp_skyline)<skyline_max_len:                                                           #add PAD       \n",
    "            temp_skyline=np.vstack((temp_skyline,PAD))\n",
    "        if len(temp_full)>max_token_len:\n",
    "            max_token_len=len(temp_full)\n",
    "        while len(temp_full)<full_max_len:\n",
    "            temp_full=np.vstack((temp_full,PAD))\n",
    "        skyline_tokens.append(temp_skyline)\n",
    "        full_tokens.append(temp_full)\n",
    "        temp_skyline=[]\n",
    "        temp_full=[]    \n",
    "    assert(len(allsong_skyline_tokens)==len(allsong_full_tokens))    \n",
    "    \n",
    "    for batch in skyline_tokens:                                                                            #stack all pages together\n",
    "        allsong_skyline_tokens.append(batch)\n",
    "    for batch in full_tokens:\n",
    "        allsong_full_tokens.append(batch)\n",
    "allsong_skyline_tokens=np.array(allsong_skyline_tokens)\n",
    "allsong_full_tokens=np.array(allsong_full_tokens)        \n",
    "assert(allsong_skyline_tokens.shape[0]==allsong_full_tokens.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93141e58-5733-4dda-8fe3-b19fb99905ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_token_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3507c8d5-55be-45a9-9860-d25190c2d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "allsong_skyline_tokens.shape,allsong_full_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "898948a2-965a-4f43-9486-ffe1d37a91f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('skyline_data/skyline_tokens.npy', 'wb') as f1:\n",
    "    np.save(f1, allsong_skyline_tokens)\n",
    "with open('skyline_data/full_tokens.npy', 'wb') as f2:\n",
    "    np.save(f2, allsong_full_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce3dbd3-0734-428e-aacc-32557fac972c",
   "metadata": {},
   "source": [
    "# Testing (reconstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceed32f8-b421-45b2-90a7-9d6df865b15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " simply to reconstruct a .mid file from any page inside skyline_tokens & full_tokens\n",
    "'''\n",
    "\n",
    "allsong_skyline_tokens=np.load('skyline_data/skyline_tokens.npy')\n",
    "allsong_full_tokens=np.load('skyline_data/full_tokens.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac50f650-c05b-4a9b-8e7e-676dd7c7ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_skyline = allsong_skyline_tokens[1]\n",
    "first_full = allsong_full_tokens[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30863d5b-6b42-42d1-838f-567b30fdfca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 4), (600, 4))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_skyline.shape, first_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a94dcfa4-c1f5-4690-aed8-f19b78e7b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token2mid(page,out_path):\n",
    "    out = mid_parser.MidiFile()\n",
    "    out.ticks_per_beat = 480\n",
    "    out.instruments = [ct.Instrument(program=0,is_drum=False,name='reduction')]\n",
    "    current_beat=-1\n",
    "    for idx,token in enumerate(page):\n",
    "        if (token==EOS).all():\n",
    "            break\n",
    "        assert((token!=PAD).all())\n",
    "        if token[0]==0 or (token==ABS).all():\n",
    "            current_beat+=1\n",
    "        if (token!=ABS).all():\n",
    "            n=token\n",
    "            out.instruments[0].notes.append(ct.Note(start=int(current_beat*4*out.ticks_per_beat+n[1]*out.ticks_per_beat/4),\n",
    "                                                        end=int(current_beat*4*out.ticks_per_beat+n[1]*out.ticks_per_beat/4+(n[3]+1)*(out.ticks_per_beat/8)),\n",
    "                                                        pitch=n[2]+22,\n",
    "                                                        velocity=90))\n",
    "    out.dump(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83e0faa8-57b0-426c-9e59-3211818bf692",
   "metadata": {},
   "outputs": [],
   "source": [
    "token2mid(first_skyline,'skylineFromToken.mid')\n",
    "token2mid(first_full,'fullFromToken.mid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
